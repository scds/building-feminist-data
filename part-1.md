---
layout: default
title: Background
nav_order: 3
---

## How does a computer understand language?

<iframe height="420" width="640" allowfullscreen frameborder=0 src="https://echo360.ca/media/dd213ce5-21f3-4e65-b771-1178c2033e45/public?autoplay=false&automute=false"></iframe>

### Learning Outcomes
By the end of this video, participants will be able to... 
	
1. Explain how language exists in digital spaces 

### Discussion Prompts
1. Computers are extraordinarily literal. If code is misspelled, for example, then computers will not be able to understand. How does this impact how computers understand language? What is the difference between conversational and literal language?  
2. How would you breakdown and describe the meaning of a contextual or qualifying statement? For example, how might a computer understand statements related to weather? What does it mean to say ‘it’s warm” or it’s ‘bright and sunny?’ Think about the ways that you would need to define these terms explicitly to a computer.  
3. As you move through the next videos in this module, consider how feminist data challenges the ways that machines understand language. Sinders asks participants, “How do we fit [intersectional] feminism inside of a database? Is it possible? How do we take something that’s a broad ideology and break it down into components? 

## What is Data?

<iframe height="420" width="640" allowfullscreen frameborder=0 src="https://echo360.ca/media/2f42a7e1-3065-4701-bfb4-242b0963804a/public?autoplay=false&automute=false"></iframe>

### Learning Outcomes
By the end of this video, participants will be able to... 
1. Define data 
2. Identify factors that contribute to the creation (or not) of datasets 

### Discussion Prompts
1. What does ‘data’ mean to you? List 2-3 examples based on your definition.
2. According to Sinders, what key characteristics define data? What is considered as data? What is not considered as data?  
3. Why do certain datasets get created and not others? What factors might contribute to a lack of data collection?
4. Is a dataset a form of documentation? How can projects like The Library of Missing Datasets be used to document exclusions, create presence, and ignite conversations about “the blank spots that exist in spaces that are otherwise data-saturated”? (Onuoha 2016)


## Data + AI

<iframe height="420" width="640" allowfullscreen frameborder=0 src="https://echo360.ca/media/fb4cb558-0448-4cba-86fa-f4e3cb2d6ddf/public?autoplay=false&automute=false"></iframe>

### Learning Outcomes
By the end of this video, participants will be able to... 
1. Identify different AI systems and their uses 
2. Explain factors that cause inaccuracies and biases in AI systems 

### Discussion Prompts
1. What is facial recognition? When and where is facial recognition used?
2. What are some examples of everyday products that use facial recognition? In what ways are these products inaccurate and biased? What factors contribute to these inaccuracies and biases?  
3. What is emotion recognition? When is emotion recognition used? Where is emotion recognition used?  
4. What are the limitations of emotion recognition? What makes emotion recognition fallible? Who defines emotion? 
5. What are the long-term consequences of using inaccurate AI systems, like facial recognition?  

## Language in Data Systems

<iframe height="420" width="640" allowfullscreen frameborder=0 src="https://echo360.ca/media/c68cc49a-395e-4ee2-9fd2-ab7cdf671980/public?autoplay=false&automute=false"></iframe>

### Learning Outcomes
By the end of this video, participants will be able to... 
1. Explain the role of bias in the creation of AI systems

### Discussion Prompts
1. What is rendered invisible when data, code and software are perceived to be neutral or objective? 
2. Sinders states that “bias is built into the system.” What does this mean? How are AI systems potentially biased?
3. How does data interact with machine learning and artificial intelligence? Why is it important to consider the data?

### Examples to Consider
1. Facebook’s chatbot, Blender, was training on Reddit data. The bot learned abusive language and was vulgar and offensive (Hunt 2016).
2. Microsoft’s AI chatbot, Tay, was trained on conversations from Twitter. It was pulled from the market after 24 hours for tweeting racist comments (BBC 2020).

*Once finished, please continue on to [the next part](part-2).*
